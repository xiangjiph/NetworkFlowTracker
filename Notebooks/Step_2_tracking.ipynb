{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, logging, datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import skimage.morphology as skim\n",
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_flow_tracker import particle\n",
    "import trackpy as tp\n",
    "from network_flow_tracker import linking as NFTLinking\n",
    "from network_flow_tracker import FlowGraph as FG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network_flow_tracker import LFBFP\n",
    "import network_flow_tracker.utils.io as io\n",
    "import network_flow_tracker.utils.vis as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group = 'Lightfield'\n",
    "dataset = 'Zhang2020'\n",
    "data_root_path = f'C:\\\\Data\\\\{data_group}\\\\{dataset}'\n",
    "process_data_root = os.path.join(data_root_path, 'processed_data')\n",
    "\n",
    "info_fp = os.path.join(process_data_root, 'data_info.pickle')\n",
    "data_info = io.load_data(info_fp)\n",
    "mm2s_to_pxl2s = 1e3 / data_info['frame_rate_Hz'] / data_info['target_voxel_size_um']\n",
    "voxel_size_um = data_info['target_voxel_size_um']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remove 12 node voxels on the sub-volume boundary\n"
     ]
    }
   ],
   "source": [
    "debug_Q = False\n",
    "rm_node_voxel_on_vol_boundary_Q = True\n",
    "z_idx = 0\n",
    "# Load the stitched mask \n",
    "z_folder_name = data_info['raw_data_folders'][z_idx]\n",
    "stitch_data_fp = os.path.join(process_data_root, 'itk', 'recon', 'whole_20250614_140908_data.mat')\n",
    "stitch_data = LFBFP.LFBFProcessing.load_and_parse_annotation_data(stitch_data_fp)\n",
    "sv_data = LFBFP.LFBFProcessing.get_subvol_data(data_info, stitch_data, z_idx)\n",
    "sv_disp_vec = sv_data['disp_vec']\n",
    "mask_size = sv_data['mask_size']\n",
    "whole_mask_size = stitch_data['mask_size']\n",
    "vsl_mips = vis.compute_three_view_mip(sv_data['im'])\n",
    "vsl_mask = sv_data['label_array'] > 0\n",
    "\n",
    "avg_hematocrit = 0.5\n",
    "cell_labeled_fraction = 0.1\n",
    "# visual check \n",
    "if debug_Q:\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot()\n",
    "    # This vascular image has been high-pass-filtered. Large vessel might have black reigon inside. \n",
    "    ax.imshow(vsl_mips['yx'], cmap='gray')\n",
    "    ax.scatter(sv_data['skl_sub'][2], sv_data['skl_sub'][1], 0.25, color='r', alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 skeleton voxels are labeled as vein in vsl_skl_labeled, but as capillary in vsl_vol_labeled. Correct to capillary.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Spatial graph with 753 edges and 402 nodes."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_r_array = np.zeros(sv_data['mask_size'], np.float16)\n",
    "skl_r_array.flat[sv_data['skl_ind']] = sv_data['skl_r_v']\n",
    "skl_label_array = np.zeros(sv_data['mask_size'], dtype=np.int8)\n",
    "skl_label_array.flat[sv_data['skl_ind']] = sv_data['skl_label_v']\n",
    "fg = FG.FlowGraph(skl_label_array > 0)\n",
    "fg.init_nearest_skl_map(vsl_skl_labeled=skl_label_array, vsl_vol_labeled=sv_data['label_array'])\n",
    "fg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish loading cell position data\n"
     ]
    }
   ],
   "source": [
    "# Here we need to match the points to the graph. \n",
    "# The sub-graph was cropped according to the regisration vector along the z direction (only!)\n",
    "# So the points need to be moved along the xy direction: \n",
    "data_disp_vec = stitch_data['disp_vec_c'].copy()\n",
    "data_disp_vec[:, 0] = 0\n",
    "lfp = LFBFP.LFBFProcessing(data_root_path, data_info)\n",
    "num_file = data_info['num_files'][z_idx]\n",
    "# Load data\n",
    "data_t_list = []\n",
    "for t_idx in range(num_file):\n",
    "    tmp_data = io.load_data(lfp.fp_cell_pos(z_idx, t_idx))\n",
    "    tmp_df, tmp_info = NFTLinking.parse_detection_data(tmp_data, vol_shape=mask_size)\n",
    "    data_t_list.append(tmp_df)\n",
    "print(\"Finish loading cell position data\")\n",
    "data_t_list = NFTLinking.register_detections(data_t_list, disp_vec=data_disp_vec[z_idx], vol_shape=mask_size, inplace_Q=True, verboseQ=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detections: 446710\n"
     ]
    }
   ],
   "source": [
    "min_peak_snr = 2\n",
    "mask_dilate_r = 2\n",
    "max_extra_dist_to_skl = 3\n",
    "# Detection selection\n",
    "detections = pd.concat(data_t_list).drop(columns=['sub_0', 'sub_1', 'sub_2', 'eig3', 'bg_std', 'nb_mean'])\n",
    "detections = detections[detections.peak_nb_snr >= min_peak_snr]\n",
    "non_bg_mask = skim.binary_dilation(vsl_mask, skim.ball(radius=mask_dilate_r))\n",
    "in_mask_Q = non_bg_mask.flat[detections.ind.values]\n",
    "detections = detections[in_mask_Q]\n",
    "\n",
    "dist_2_skl = fg.nearest_map.ind_to_nearest_dist(detections.ind.values)\n",
    "nearest_skl_r = skl_r_array.flat[detections.ind.values]\n",
    "near_skl_Q = (dist_2_skl <= nearest_skl_r + max_extra_dist_to_skl)\n",
    "detections = detections[near_skl_Q]\n",
    "\n",
    "detections = detections.reset_index(drop=True)\n",
    "# Add information\n",
    "detections['skl_ind'] = fg.nearest_map.ind_to_nearest_ind(detections.ind.values)\n",
    "detections['edge_label'] = fg.edge.ind_to_label(detections['skl_ind'].values)\n",
    "detections['node_label'] = fg.node.ind_to_label(detections['skl_ind'].values)\n",
    "# Define unique detection id \n",
    "detections['did'] = np.arange(detections.shape[0], dtype=np.int64)\n",
    "\n",
    "print(f\"Number of detections: {detections.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lk_hdl = NFTLinking.Linking(detections, mask_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stalled particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max search speed: 0.28 mm/s\n",
      "Finish processing frame 1257. Finish tracking cells. \n",
      "Found 3230 trajectories of length at least 1\n",
      "Found 3230 trajectories of length at least 1\n",
      "Found 49 high count connected components.\n",
      "Got 78 trajectories\n",
      "Number of accepted traces: 78\n"
     ]
    }
   ],
   "source": [
    "search_r = 3\n",
    "min_vxl_detect = int(1 * data_info['frame_rate_Hz'])\n",
    "min_select_trace_length = 1\n",
    "min_hccc_max_length = 10\n",
    "max_time_gap = 5\n",
    "min_stationary_trace_length = 0.3 * data_info['frame_rate_Hz']\n",
    "\n",
    "max_speed_pxl = 2\n",
    "print(f\"Max search speed: {max_speed_pxl / mm2s_to_pxl2s:.2f} mm/s\")\n",
    "\n",
    "stalled_particles = NFTLinking.track_stationary_particles(lk_hdl.data, mask_size=mask_size, min_vxl_detect=min_vxl_detect, \n",
    "                                                                    max_speed_pxl=max_speed_pxl, search_r=search_r, \n",
    "                                                                    min_trace_length=min_select_trace_length, \n",
    "                                                                    min_hccc_max_length=min_hccc_max_length,\n",
    "                                                                    max_time_gap=max_time_gap, \n",
    "                                                                    min_final_trace_length=min_stationary_trace_length)\n",
    "print(f\"Got {len(stalled_particles)} trajectories\")\n",
    "lk_hdl.update_with_particles(stalled_particles, inplace_Q=True)\n",
    "active_did = lk_hdl.get_active_did(relabel_pid_Q=False, include_particle_endpoints_Q=False)\n",
    "active_detections = lk_hdl.data.iloc[active_did].sort_values(by='did')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug_Q:\n",
    "    stalled_p_pos_zyx = np.vstack([p.pos_zyx for p in stalled_particles])\n",
    "    fig = vis.vis_mips(vsl_mips, stalled_p_pos_zyx.T, fig_title=f\"{z_folder_name} # stalled cell: {len(stalled_particles)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge-based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish processing edge 700. \n",
      "Finish analyzing edge detection map.\n"
     ]
    }
   ],
   "source": [
    "# Find the high-count vessel without reliable velocity estimation \n",
    "high_freq_ccf = 1 - np.exp(-3/4 * avg_hematocrit * cell_labeled_fraction * 1)\n",
    "dm_a_para = {'init_bin_size': 2, 'init_dt': 1, 'min_num_div': 3, 'max_num_div': 15, 'max_dt': 16, \n",
    "             'min_peak_corr': 0.05, \n",
    "             're_est_min_tot_cor_r': 3, \n",
    "             'high_freq_ccf': high_freq_ccf}\n",
    "\n",
    "dm_select_para = {'min_tot_corr_r': 2, 'min_major_corr': 0.25, 'max_cv': 0.8, 'max_ok_std': 2}\n",
    "\n",
    "para_hfs = {'min_high_v': 10, 'min_hc_num': 1}\n",
    "\n",
    "dm_a_adj_e_para = {\n",
    "    'min_peak_corr': dm_a_para['min_peak_corr'], \n",
    "    'min_tot_corr_r': dm_select_para['min_tot_corr_r'], \n",
    "    'min_major_corr': dm_select_para['min_major_corr'], \n",
    "    'min_v2l': 0.75, \n",
    "    'vis_Q': False\n",
    "}\n",
    "dm_log, dm_avg_v, dm_v_std = NFTLinking.estimate_flow_velocity_using_detection_map(fg, active_detections, para_dm=dm_a_para, \n",
    "                                                                                                     para_dms=dm_select_para, para_hfs=para_hfs, \n",
    "                                                                                                     para_mea=dm_a_adj_e_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_reliable_edge_Q = np.isnan(dm_avg_v)\n",
    "non_reliable_v_ind = np.concatenate(fg.edge.cc_ind[non_reliable_edge_Q])\n",
    "non_reliable_v_sub = fg.ind2sub(non_reliable_v_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track moving particles "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph-guided tracking without prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max search speed: 2.10 mm/s\n",
      "Finish configuring trackpy query function.  {'search_range': 15, 'num_nb': 10, 'max_exit_travel': 0, 'predictQ': False, 'gdistQ': True, 'v_error_frac': 0.5, 'v_error_min': 5, 'compare_feature': [], 'feature_cost_max': 10}\n",
      "Finish processing frame 1257. Finish tracking cells. \n"
     ]
    }
   ],
   "source": [
    "max_speed_pxl = 15 # ~ 2 mm/s\n",
    "print(f\"Max search speed: {max_speed_pxl / mm2s_to_pxl2s:.2f} mm/s\")\n",
    "fg.configure_trackpy_query(search_range=max_speed_pxl, num_nb=10, predictQ=False)\n",
    "trace_result = NFTLinking.tracking(active_detections, max_speed_pxl, pos_col=['z', 'y', 'x'], dist_func=fg.trackpy_query, output_type='table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 39361 trajectories of length at least 3\n",
      "Finish processing trace 39350. Found 15660 valid trajectories of length at least 3\n",
      "Finish constructing voxel speed map using (15651 of 15660) traces. \n",
      "Finish constructing skeleton speed map.\n",
      "Finish analyzing flow velocity in edge 710. \n",
      "Finish analyzing edge velocity from the tracking result\n"
     ]
    }
   ],
   "source": [
    "# trace selection \n",
    "para_ts = {'mask_size': mask_size, \n",
    "           'min_length': 3, \n",
    "           'min_cos': 0.25, \n",
    "           'min_med_cos': 0.75, \n",
    "           'max_ignore_v': 2} \n",
    "# tracking-based edge velocity estimation \n",
    "para_teve = {'gm_max_num_est': 3,  # maximum number of mixture-of-gaussian fitting (random initialization) \n",
    "             'min_data_size': 5,  # minimal data size for fitting\n",
    "             'min_gmc_dist_std_n': 2} # minimal mixture-of-gaussian normalized mean difference. If 2 components fit the distribution better but their spacing is smaller than this value, re-do the fitting\n",
    "para_teves = {'min_weight_ratio': 1.5, \n",
    "              'min_track_fraction': 0.3, \n",
    "              'max_abs_cv': 0.8, \n",
    "              'max_std_to_ignore_cv': 1}\n",
    "\n",
    "edge_tk_v_results, edge_trkb_v, edge_trkb_v_std = NFTLinking.estimate_flow_velocity_using_tracking(fg, trace_result, para_ts, para_teve, para_teves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge 151 has v_t greater than the maximum corr-based estimatable velocity. Use tracking-based velocity. \n",
      "Edge 328 v_corr -10.83 +/- 2.00, v_t -6.42 +/- 2.33\n",
      "Edge 432 has v_t greater than the maximum corr-based estimatable velocity. Use tracking-based velocity. \n",
      "Edge 656 has v_t greater than the maximum corr-based estimatable velocity. Use tracking-based velocity. \n",
      "Edge 671 has v_t greater than the maximum corr-based estimatable velocity. Use tracking-based velocity. \n",
      "Number of edges without any good velocity estimation: 128\n",
      "Number of edges with at least one good velocity estimation: 624\n"
     ]
    }
   ],
   "source": [
    "para_cb_w = {'max_tk_v': 0.75 * max_speed_pxl, \n",
    "             'min_std': 2, \n",
    "             'max_v_diff_z': 2, \n",
    "             'min_nonzero_v': 1, \n",
    "             'log_conflict_Q': True}\n",
    "\n",
    "edge_v_info_0 = NFTLinking.combine_initial_edge_v_estimation(dm_log, dm_avg_v, dm_v_std, edge_trkb_v, edge_trkb_v_std, **para_cb_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 39 has outflow edge [62 81] and no known inflow edge. Infer edge 61 to have velocity 30.303467542325173\n",
      "Node 60 has outflow edge [ 96 141] and no known inflow edge. Infer edge 103 to have velocity -65.21193196131763\n",
      "Node 64 has inflow edge [115 135] and no known outflow edge. Infer edge 136 to have velocity 26.684957044330496\n",
      "Node 123 has inflow edge [250 262] and no known outflow edge. Infer edge 127 to have velocity -11.679630970112004\n",
      "Node 208 has outflow edge [392 410] and no known inflow edge. Infer edge 405 to have velocity -10.410808827512554\n",
      "Node 219 has inflow edge [ 39 280] and no known outflow edge. Infer edge 430 to have velocity 15.149214834057302\n",
      "Node 229 has inflow edge [232 449] and no known outflow edge. Infer edge 412 to have velocity -4.3065725645139965\n",
      "Node 247 has inflow edge [478 479 487] and no known outflow edge. Infer edge 355 to have velocity -13.516225302427822\n",
      "Node 264 has inflow edge [492 517] and no known outflow edge. Infer edge 328 to have velocity -12.484190234377257\n",
      "Node 270 has inflow edge [498 526] and no known outflow edge. Infer edge 527 to have velocity 6.812502302531647\n",
      "Node 301 has inflow edge [399 576] and no known outflow edge. Infer edge 507 to have velocity -12.716046225492509\n",
      "Node 337 has outflow edge [379 645] and no known inflow edge. Infer edge 633 to have velocity -10.570816567447261\n",
      "Node 347 has outflow edge [311 670] and no known inflow edge. Infer edge 669 to have velocity -20.916609918063056\n",
      "Node 368 has inflow edge [679 689] and no known outflow edge. Infer edge 680 to have velocity -8.029687598799994\n",
      "Node 387 has outflow edge [306 709] and no known inflow edge. Infer edge 721 to have velocity -3.578549264414555\n",
      "Inferred flow velocity in 15 edges\n",
      "Node 53 has inflow edge [118 127] and no known outflow edge. Infer edge 98 to have velocity -11.679630970112004\n",
      "Node 269 has inflow edge [430 507] and no known outflow edge. Infer edge 524 to have velocity 15.149214834057302\n",
      "Node 360 has inflow edge [680 681] and no known outflow edge. Infer edge 482 to have velocity -15.464275332468864\n",
      "Inferred flow velocity in 3 edges\n",
      "Node 243 has inflow edge [468 482] and no known outflow edge. Infer edge 429 to have velocity -15.464275332468864\n",
      "Node 331 has inflow edge [524 615] and no known outflow edge. Infer edge 626 to have velocity 18.65824984960545\n",
      "Inferred flow velocity in 2 edges\n",
      "Node 218 has inflow edge [412 429] and no known outflow edge. Infer edge 406 to have velocity -15.464275332468864\n",
      "Inferred flow velocity in 1 edges\n",
      "Node 203 has inflow edge [396 406] and no known outflow edge. Infer edge 166 to have velocity -15.464275332468864\n",
      "Inferred flow velocity in 1 edges\n",
      "Inferred flow velocity in 0 edges\n"
     ]
    }
   ],
   "source": [
    "edge_v_info_1 = edge_v_info_0\n",
    "while True: \n",
    "    edge_v_info_1 = fg.infer_edge_velocity_by_node_flow_configuration(edge_v_info_1['v'], edge_v_info_1['std'], verbose_Q=True)\n",
    "    if len(edge_v_info_1['inferred_edge']) == 0: \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction based tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish configuring trackpy query function.  {'search_range': 20, 'num_nb': 10, 'max_exit_travel': 0, 'predictQ': True, 'gdistQ': True, 'v_error_frac': 0.75, 'v_error_min': 10, 'compare_feature': ['peak_int'], 'feature_cost_max': 10}\n"
     ]
    }
   ],
   "source": [
    "# trace selection \n",
    "para_ts = {'mask_size': mask_size, \n",
    "           'min_length': 3, \n",
    "           'min_cos': 0.25, \n",
    "           'min_med_cos': 0.75, \n",
    "           'max_ignore_v': 2} \n",
    "\n",
    "para_evu = {'max_v_diff_z': 2, \n",
    "            'min_nonzero_v': 1, \n",
    "            'min_std': 1, \n",
    "            'min_tk_f': 0.1, \n",
    "            'min_trust_f': 0.5, \n",
    "            'allow_conflicting_Q': True\n",
    "            }\n",
    "max_speed_pxl = 20\n",
    "v_error_frac = 0.75\n",
    "v_error_min = 10\n",
    "feature_list = ['peak_int']\n",
    "result_log = []\n",
    "\n",
    "fg.configure_trackpy_query(search_range=max_speed_pxl, num_nb=10, max_exit_travel=0, predictQ=True, v_error_frac=0.75, v_error_min=10, compare_feature=feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start the 1 round of prediction-based tracking\n",
      "\n",
      "Finish processing frame 1257. Finish tracking cells. \n",
      "Found 11145 trajectories of length at least 3\n",
      "Finish processing trace 11100. Found 5680 valid trajectories of length at least 3\n",
      "Finish constructing voxel speed map using (5671 of 5680) traces. \n",
      "Finish constructing skeleton speed map.\n",
      "Finish analyzing flow velocity in edge 710. \n",
      "Finish analyzing edge velocity from the tracking result\n",
      "Edge 610: 9.2 +/- 2.6, 19.6 +/- 5.5 does not make sense\n"
     ]
    }
   ],
   "source": [
    "for p_est_count in range(1):\n",
    "    print(f\"Start the {p_est_count + 1} round of prediction-based tracking\\n\")\n",
    "    if p_est_count == 0: \n",
    "        curr_v = edge_v_info_1['v']\n",
    "        curr_std = edge_v_info_1['std']\n",
    "        curr_track_frac = None\n",
    "    else: \n",
    "        curr_v_info = result_log[p_est_count - 1]['edge_v_info']\n",
    "        curr_v = curr_v_info['v']\n",
    "        curr_std = curr_v_info['std']\n",
    "        curr_track_frac = curr_v_info['track_frac']\n",
    "\n",
    "    fg.init_velocity(curr_v, curr_std, curr_track_frac)\n",
    "    ptrace_result = NFTLinking.tracking(active_detections, max_speed_pxl, pos_col=['z', 'y', 'x'], feature_col=feature_list, dist_func=fg.trackpy_query, output_type='table')\n",
    "    p_edge_tk_info_0, pedge_trkb_v, pedge_trkb_v_std = NFTLinking.estimate_flow_velocity_using_tracking(fg, ptrace_result, para_ts, para_teve, para_teves)\n",
    "    \n",
    "    p_edge_tk_info = p_edge_tk_info_0.copy()\n",
    "    p_edge_tk_info['est_v'] = pedge_trkb_v\n",
    "    p_edge_tk_info['est_v_std'] = pedge_trkb_v_std\n",
    "\n",
    "    updated_e_v_info = NFTLinking.update_edge_flow_estimation(curr_v, curr_std, curr_track_frac, p_edge_tk_info, **para_evu)\n",
    "    log_result = {'iteration': p_est_count, 'table': ptrace_result, 'edge_tk_info': p_edge_tk_info, 'edge_v_info': updated_e_v_info}\n",
    "    result_log.append(log_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of accepted traces: 29574\n"
     ]
    }
   ],
   "source": [
    "time_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "data_dict = {}\n",
    "data_dict['date'] = time_str\n",
    "data_dict['graph_version'] = stitch_data_fp\n",
    "data_dict['data_group'] = data_group\n",
    "data_dict['dataset'] = dataset\n",
    "data_dict['data_info'] = data_info\n",
    "data_dict['tracking_all'] = NFTLinking.merge_detection_table(lk_hdl.data.copy(), ptrace_result)\n",
    "data_dict['tracking_ns'] = ptrace_result\n",
    "data_dict['num_pt_iter'] = len(result_log)\n",
    "data_dict['sv_data'] = sv_data\n",
    "data_dict['skl_vsl_map'] = fg.vxl_speed_map\n",
    "data_dict['e_ep_ind'] = np.vstack([ind[[0, -1]] for ind in fg.edge.cc_ind])\n",
    "data_dict['edge_v_pxl'] = fg.edge_v_pxl\n",
    "data_dict['edge_v_std_pxl'] = fg.edge_v_std_pxl\n",
    "data_dict['edge_track_frac'] = fg.edge_track_frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(process_data_root, 'tracking')\n",
    "data_fp = os.path.join(data_folder, f\"{data_info['raw_data_folders'][z_idx]}_tk_w_pdt_{data_dict['date']}.pickle\")\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "io.save_data(data_fp, data_dict)\n",
    "print(f\"Finish saving {data_fp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NFT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
